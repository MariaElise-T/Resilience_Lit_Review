Due to persistent and serious threats from natural disasters around the globe, many have turned to resilience and vulnerability research to guide disaster preparation, recovery, and adaptation decisions. In response, scholars and practitioners have put forth a variety of disaster indices, based on quantifiable metrics, to gauge levels of resilience and vulnerability. However, few indices are empirically validated using observed disaster impacts and, as a result, it is often unclear which index should be preferred for each decision at hand. Thus, we compare and empirically validate five of the top U.S. disaster indices, including three resilience indices and two vulnerability indices. We use observed disaster losses, fatalities, and disaster declarations from the southeastern United States to empirically validate each index. We find that disaster indices, though thoughtfully substantiated by literature and theoretically persuasive, are not all created equal. While four of the five indices perform as predicted in explaining damages, only three explain fatalities and only two explain disaster declarations as expected by theory. These results highlight the need for disaster indices to clearly state index objectives and structure underlying metrics to support validation of the results based on these goals. Further, policymakers should use index results carefully when developing regional policy or investing in resilience and vulnerability improvement projects.