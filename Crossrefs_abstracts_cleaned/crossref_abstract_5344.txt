To ensure the sustainability of the future power grid, the rate of expansion of distributed energy resources (DERs) has introduced operational challenges. These include managing transmission constraints with DER power injection, dispatching DERs efficiently, managing system frequency, and ensuring sufficient reactive power for voltage support. Coupled with the intensification of wildfires, power infrastructures across the United States face challenges to minimize the impact of these factors and maintain system reliability and resiliency. This research embarked on a comprehensive evaluation, beginning with an in-depth historical analysis to delineate regions most susceptible to wildfires. Utilizing a multidimensional approach, the study assessed wildfire-induced risks to power grids by integrating historical wildfire occurrences, real-time wildfire proximities, Moderate-Resolution Imaging Spectroradiometer (MODIS)-derived vegetation metrics, and system parameters. Principal component analysis (PCA)-based optimal weights were then used, leading to the formulation of a novel risk factor model. This risk factor model has the potential to be the key to ensuring the resilience of a renewable-rich smart grid when faced with a severe weather event. Our modelâ€™s applicability was further verified through an empirical assessment, selecting representative networks from diverse regions, providing insights into the geographical variability of risk factors. Ultimately, this study offers stakeholders and policymakers a comprehensive toolset, empowering decisions regarding infrastructure investments, grid reinforcements, and strategic power rerouting to ensure consistent energy delivery during wildfires.