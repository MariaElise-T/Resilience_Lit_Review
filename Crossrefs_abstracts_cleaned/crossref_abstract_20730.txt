 Algorithmic discrimination poses an increased risk to the legal principle of equality. Scholarly accounts of this challenge are emerging in the context of EU equality law, but the question of the resilience of the legal framework has not yet been addressed in depth. Exploring three central incompatibilities between the conceptual map of EU equality law and algorithmic discrimination, this article investigates how purposively revisiting selected conceptual and doctrinal tenets of EU non-discrimination law offers pathways towards enhancing its effectiveness and resilience. First, I argue that predictive analytics are likely to give rise to intersectional forms of discrimination, which challenge the unidimensional understanding of discrimination prevalent in EU law. Second, I show how proxy discrimination in the context of machine learning questions the grammar of EU non-discrimination law. Finally, I address the risk that new patterns of systemic discrimination emerge in the algorithmic society. Throughout the article, I show that looking at the margins of the conceptual and doctrinal map of EU equality law offers several pathways to tackling algorithmic discrimination. This exercise is particularly important with a view to securing a technology-neutral legal framework robust enough to provide an effective remedy to algorithmic threats to fundamental rights. 